[["index.html", "BioCro Development Introduction Note about the types of documentation in BioCro The online documentation Version Info", " BioCro Development Version info Introduction The documentation in this short book is aimed at developers—at those who will be writing new modules or modifying existing ones; and most especially at those fixing bugs in or adding new features to the BioCro simulation framework, and those involved with the overall maintenance of the BioCro package. Note about the types of documentation in BioCro There several categories of documentation for BioCro: The top-level README.md is for general information about BioCro and is intended for potential users of the package. The files in man directory document the R functions and the data associated with the BioCro package and are intended for users of the package. The files in the vignettes directory are generally “longform” documentation, also intended for users of the package. There is the documentation generated by Doxygen, generally from comments in the C++ source files. This is of interest to developers, but general users may also be interested, particularly in the documentation of the various BioCro modules. Finally, there are various .md or .Rmd files scattered about the package that are referenced by the bookdown/_bookdown.yml configuration file, and that can be compiled into a book (this book, if you are reading this page in bookdown) using the bookdown package. This documentation is targeted at BioCro developers and maintainers. The online documentation Each of the above categories of documentation is available online at https://ebimodeling.github.io/biocro-documentation/, the landing page for various versions of the online documentation of the code in the ebimodeling/biocro repository.1 The URL for the latest version of the master branch is https://ebimodeling.github.io/biocro-documentation/master/pkgdown/index.html. When online documentation is generated Documentation is automatically generated when The master branch of the repository on GitHub is updated. This version of the documentation lives at https://ebimodeling.github.io/biocro-documentation/master/pkgdown/index.html. A version of the repository’s history is tagged, and that tag is pushed to the GitHub repository. Each tagged version’s documentation lives at a URL of the form https://ebimodeling.github.io/biocro-documentation/&lt;tag name&gt;/pkgdown/index.html. A pull request is created or updated. In this case, the documentation is generated and packaged as a Zip file available for download but is not deployed online. To download such a file, go to https://github.com/ebimodeling/biocro/actions/workflows/automatically-call-document.yml and find a workflow run corresponding to the pull request whose documentation you wish to view. Click on it, and then find the artifact to download near the bottom of the page.2 In addition, one can always manually trigger a workflow build of the documentation for a specific branch. You can either have it deployed, or merely built for download. One can also choose which types of documentation to generate. (See the introductory section about types of documentation for discussion of the various types of BioCro documentation.) If you choose to deploy the branch documentation, the result will live at a URL of the form https://ebimodeling.github.io/biocro-documentation/&lt;branch name&gt;/pkgdown/index.html. The layout of the online documentation The layout of the online documentation is in the form of a pkgdown document. Each of the categories of documentation listed above corresponds to a portion of this document as follows: The README.md document appears on the pkgdown home page (BioCro in the menu). The man pages appear under the menu item References. (Note that although the page heading on this page says Function reference, documentation of the various data sets is included as well.) The vignettes appear under the menu item Articles. The Doxygen documentation appears under the menu item C++ Library. Note that there are various forms of this documentation of varying concision and comprehensiveness.3 The developer documentation (this book!) appears under the menu item Developer’s Manual.4 Note that the Developer’s Manual, the C++ documentation, and the PDF-style vignettes are not well integrated into pkgdown, and the user will have to click the browser back button to return to pkgdown proper to once again have access to the pkgdown menu items. In addition to the documentation proper, the menu bar contains some other useful links: The About page gives useful information about the documentation—namely, which branch and commit version it corresponds to and the commit and generation dates. The Changelog shows the BioCro version history. Finally, there is a search box at the right of the menu bar. Note that this will not search the portions of the documentation not integrated into pkgdown, that is, it will not search the Developer’s Manual, the C++ documentation, or the PDF-style vignettes. And the search box only functions when pkgdown is deployed on a server. Version Info This document was generated from the version of BioCro specified as follows: Commit Hash: 7d1ca55 Commit Date: Wed, 25 Oct 2023 21:12:41 -0500 Branch: merge-resolution Generation Time: Thu, 26 Oct 2023 02:48:38 +0000 Note that this page does not necessarily contain links to all available versions of the documentation: it is generated from the file README.md at the top level of the ebimodeling/biocro-documentation GitHub repository, and it must be updated manually to change the links that appear. See the section When online documentation is generated for information about the URLs for various generated versions.↩︎ If there is more than one run for a given pull request, you will probably want the latest one. If the Zip file has expired, you may have to manually call the workflow to regenerate it. (Be sure to choose to run the workflow on the branch corresponding to the pull request you are interested in.) Manually-triggered workflow runs may be found at https://github.com/ebimodeling/biocro/actions/workflows/automatically-call-document.yml↩︎ If you manually generate the Doxygen documentation without generating the pkgdown framework, you can access the Doxygen documents directly by using URLs of the form https://ebimodeling.github.io/biocro-documentation/&lt;branch name&gt;/doxygen/&lt;version&gt;/index.html, where &lt;version&gt; is one of doxygen_docs_complete, doxygen_docs_framework, doxygen_docs_modules, or doxygen_docs_modules_public_members_only.↩︎ If you manually generate the developer (Bookdown) documentation without generating the pkgdown framework, you can access the Bookdown book directly by using URLs of the form https://ebimodeling.github.io/biocro-documentation/&lt;branch name&gt;/bookdown/index.html.↩︎ "],["contributing-to-biocro.html", "1 Contributing to BioCro 1.1 Making Changes 1.2 Code style 1.3 Formatting Tools", " 1 Contributing to BioCro 1.1 Making Changes 1.1.1 Discuss first Check the list of GitHub issues for a discussion of the issue. If there is not one, create an issue with a description of the problem and your proposed solution. By making changes without discussing it with the group, you risk spending time working on a solution that others may not accept. The members of the group also have diverse backgrounds and likely can give valuable design insights. 1.1.2 Making large modifications to BioCro From time to time, someone will propose making a large change to the organizational structure of BioCro or to one of its central components. Here we also consider any modification that influences the way users or developers interact with BioCro to be “large.” Large changes must be carefully considered and discussed before they are implemented. When considering such proposals, a number of key points should be kept in mind: BioCro is designed for computational modelers who want to focus on biology rather than computer programming; it is essential for BioCro to be easy to install and use. A friendly user experience makes BioCro accessible to a wide range of users who each have the potential to contribute to broader scientific understanding through modeling. Thus, it is important to minimize any barriers that may prevent some scientists from using it. BioCro is developed and maintained by a small team, most of whom have numerous other responsibilities. Thus, it is important to carefully consider the implementation and maintenance costs that may be associated with any proposed change, carefully weighing these against the perceived benefits. Changes to BioCro R packages should be consistent with CRAN policies. Distributing BioCro via CRAN is a key part of keeping it accessible to all users with maximum ease. At its core, BioCro is a C++ library; the BioCro R package merely provides a convenient R interface. Even though this R interface exists, we wish the C++ core to remain usable on its own. This has two implications: The core C++ library should maintain a consistent interface. Any changes to the public API should be carefully considered and carefully delineated.5 It should be and should remain relatively painless to obtain and use this library without having to have a full R installation. With BioCro, a premium is put on keeping it relatively self-contained; needless dependencies should be avoided. There are a number of reasons for this: Limiting dependencies will make it less likely BioCro will break for reasons beyond our control. Limiting dependencies reduces security risks. (On this point see, for example, Russ Cox’s discussion of the 2017 Equifax fiasco in his article Our Software Dependency Problem.) Limiting dependencies makes reproducibilty easier. If one wishes to replicate results of a BioCro simulation, the task is more difficult if one has to worry not only about what platform, what version of R, and what version of BioCro were used to obtain the original results, but if, on top of that, one has to worry about the versions of other R packages depended upon.6 Limiting dependencies means that fewer steps are required to install BioCro. BioCro has few dependencies, and all things being equal, we would like to keep it that way.7 If you propose a large modification to BioCro, please be prepared to discuss the following questions: How will time costs change for maintainers, developers, and users? Will there be more or fewer opportunities for BioCro to break due to changes in its dependencies? Which BioCro features will be added or lost? 1.2 Code style (Most of what is discussed here pertains specifically to code for the BioCro C++ library.) 1.2.1 Scientific considerations 1.2.1.1 Document sources and justifications in the code Include citations to sources for equations and parameters used in the code. The citation should be sufficient to locate the article and relevant information within it. Include a table or figure reference if appropriate. Use Doxygen-style comment syntax for high-level documentation of functions and classes. We use the Javadoc style of comment block in our code. (See the documentation of the Solar Position module solar_position_michalsky for an example of a Doxygen-style comment, and then look at the way this is rendered in the generated documentation.) Include reasoning and justification for the model, including assumptions that determine when use of the model is appropriate. These descriptions should be succinct. 1.2.1.2 Document units in the code After every physical quantity, include a comment with the units. The idea is that every quantity will roughly be read as if it were written in normal text: for example, double yield = 10 // Mg / ha should be read as meaning “the yield was 10 Mg / ha”. Using dimensions instead of units is acceptable if the code is written with the expectation that coherent units are used. The following example shows how to indicate units in a number of different contexts. Note that, as in LaTeX, ^ is used to indicate a superscript, so that m^2 indicates square meters. // In function signatures double ball_berry(double assimilation, // mol / m^2 / s double atmospheric_co2_concentration, // mol / mol double atmospheric_relative_humidity, // Pa / Pa double beta0, // mol / m^2 / s double beta1) // dimensionless from [mol / m^2 / s] / [mol / m^2 / s] // In assignments double leaf_temperature = air_temperature - delta_t; // K. // In return statements return assimilation_rate; // micromoles / m^2 / s. // In tables const std::map&lt;SoilType, soilText_str&gt; soil_parameters = { // d = dimensionless // d d d J / kg d J s / m^3 d d d Mg / m^3 // silt clay sand air_entry b Ks satur fieldc wiltp bulk_density { SoilType::sand, { 0.05, 0.03, 0.92, -0.7, 1.7, 5.8e-3, 0.87, 0.09, 0.03, 1.60 } }, { SoilType::loamy_sand, { 0.12, 0.07, 0.81, -0.9, 2.1, 1.7e-3, 0.72, 0.13, 0.06, 1.55 } }, }; If you would like to include other details, include the units in the same way, and include details following the units so that the variables are still read like regular text. For example, write ✓ return gswmol * 1000; // mmol / m^2 / s. Convert from mol to mmol. not ✗ return gswmol * 1000; // Converting from mol / m^2 / s to mmol / m^2 / s. Note that in a case such as this, the units apply to the entire value (gswmol * 1000) and not merely to the variable (gswmol). Use SI conventions for units and dimensions, including capitalization. Specifically, use “degrees C”, not “C”, to indicate °C. Use full names when symbols are not available: micromoles / m^2, not umol / m^2 degrees C, not *C. Use dimensionless for dimensionless quantities, and include how the dimensions have canceled if that is informative. Use ^ to indicate exponentiation: m^2, not m2. Prefer an asterisk to indicate multiplication; but indicating multiplication by juxtaposing units with exactly one space between them is acceptable. Prefer exactly one space on each side of the asterisk: kg * m / s or kg m / s. Either a solidus (“/”) or negative exponent is acceptable to indicate division, but ensure that the solidus is used correctly if used multiple times. Prefer exactly one space on each side of the solidus. 1.2.1.3 Document parameters When adding models that require new parameters, document the parameters in the parameter table in src/parameters.h. Please keep the table well formatted. If you are working on a model with undocumented parameters, it would be nice if you added them to the table as you work through the issue. 1.2.2 General coding considerations Do not use C-style arrays. Use an appropriate data type from the standard library instead. Use cmath, not math.h, for common mathematical functions. Be careful with using-directives (e.g. using namespace std) in a global scope; do not use them in global scope in a header file. Try to make using-declarations (e.g. using std::string) as local as possible. Type aliases (e.g. using string_vector = std::vector&lt;std::string&gt;) are perfectly acceptable in the global scope of a header file. Strongly prefer the coherent set of SI units. Doing so reduces code complexity remarkably as no conversions are necessary. Yes, no one publishes values with these units, but do the conversion in one place, the manuscript, instead of dozens of times in the code, constantly having to look up units for variables, and then spending hours debugging silly, difficult-to-find errors. The coherent set of SI units consists of all the units without prefixes, except that kg is the coherent unit of mass, not g. Do not copy and paste code, changing only small parts. Choose a design that eliminates the duplication. Duplication is often the result of not separating control flow from data. Consider the following R code. if (!(&quot;lattice&quot; %in% installed.packages()[,&quot;Package&quot;])) { install.packages(&quot;lattice&quot;, repos=&quot;http://R-Forge.R-project.org&quot;, type=&quot;source&quot;) } if (!(&quot;BioCro&quot; %in% installed.packages()[,&quot;Package&quot;])) { devtools::install_github(&quot;ebimodeling/biocro&quot;) } if (!(&quot;boot&quot; %in% installed.packages()[,&quot;Package&quot;])) { devtools::install_url(&quot;http://cran.r-project.org/src/contrib/Archive/boot/boot_1.3-7.tar.gz&quot;) } The data and behavior can be separated. required_packages = list( # package name # installation function # function arguments list(&quot;lattice&quot;, install.packages, list(&quot;lattice&quot;, repos=&quot;http://R-Forge.R-project.org&quot;, type=&quot;source&quot;)), list(&quot;BioCro&quot;, devtools::install_github, list(&quot;ebimodeling/biocro&quot;)), list(&quot;boot&quot;, devtools::install_url, list(&quot;http://cran.r-project.org/src/contrib/Archive/boot/boot_1.3-7.tar.gz&quot;)) ) install_packages_if_missing = function(package_table) { installed_packages = installed.packages()[,&quot;Package&quot;] for (row in package_table) { if (!(row[[1]] %in% installed_packages)) { do.call(row[[2]], row[[3]]) } } } install_packages_if_missing(required_packages) In the first example, the behavior is spread throughout all of the code, and there is not an obvious indication of what is being done. Once one understands what is being done, one must still read all of the code to be sure some different behavior is not hidden somewhere. In the second example, it is clear that the same task is performed repeatedly because control flow is in a single place, and the place has a meaningful name: install_packages_if_missing. For a long list, this is succinct, and easier to understand and maintain. If one wanted, one could devise a way to use the meaningful names of the columns of the required_packages table within the function. Make an effort to write unit tests. (See the vignette An Introduction to BioCro for Those Who Want to Add Models for information about writing unit tests—specifically, writing unit tests for new modules.) Do not mix sweeping formatting changes with behavior changes. Large formatting changes should be a separate commit, containing only formatting changes, and the commit comment should indicate that only formatting was changed. This way, code that changes program behavior won’t be obscured by a mass of changes to the formatting of the code. The Standard C++ Foundation’s [C++ Core Guidelines][] have useful advice about aspects of coding and design. 1.2.3 Formatting code (Again, except in a few instances, this pertains specifically to C++ code.) The most important aspect of formatting is that the code is easy to understand. Below are unenforced preferences. Prefer underscores_in_identifiers not CamelCaseInIdentifiers and, in R, not dots.in.identifiers. Prefer lowercase-only identifiers. An exception may be made for commonly-recognized names used in a small scope, for example, I = V / R; F = m * a; E = m * (c * c); Avoid unnecessary parentheses. For example, use “a * b / c” instead of “(a * b) / c” or “a * (b / c)”. But in cases where the order of operations affects the result, parentheses may be used to erase any doubt in the mind of the reader (or the programmer!) as to what that order is. Thus, writing (a / b) * c instead of (the equivalent) a / b * c is acceptable. Parentheses may also be used to group portions of a formula that are commonly considered as a sub-unit, where they provide some semantic value (see the previous bullet point). Consider naming parts of a complicated expression in order to break it down into simpler ones. For example, x = (-b + sqrt(b * b - 4 * a * c)) / (2 * a); may be rewritten in three lines as num = -b + sqrt(b * b - 4 * a * c); denom = 2 * a; x = num / denom; Note that in C++, unlike in R, return statements do not require parentheses around the returned expression. Restrict the line length of paragraph-like comments to 80 characters, excepting a compelling reason to do otherwise. Lines in sections that are not paragraph-like could be somewhat longer if it facilitates presenting material in a more readable format. In the following snippet from the module library documentation, for example, we have allowed slighly-longer lines in order to be able to maintain one line per interval: /* * However, this definition is flexible. For example, for our soybean model * (soybean_development_rate_calculator.h) we define the intervals as follows: * -1 &lt;= DVI &lt; 0 : Sowing to Emergence * 0 &lt;= DVI &lt; 1 : Emergence to R1 (Flowering) is broken into three stages. * 0 &lt;= DVI &lt; 0.333 : Emergence to V0 (Cotyledon stage) * 0.333 &lt;= DVI &lt; 0.667 : V0 (Cotyledon stage) to R0 (End of Floral Induction) * 0.667 &lt;= DVI &lt; 1 : R0 (End of Floral Induction) to R1 (Flowering) * 1 &lt;= DVI &lt; 2 : R1 (Flowering) to R7 (Maturity) */ As for the code lines themselves, we point to the following advice from the Linux kernel project:1 The preferred limit on the length of a single line is 80 columns. Statements longer than 80 columns should be broken into sensible chunks, unless exceeding 80 columns significantly increases readability and does not hide information. Do not include trailing whitespace, i.e., whitespace characters preceding newline characters. Each file should end with a newline character (i.e. a terminal endline). Use spaces rather than tab characters. In general, formatting preferences should follow something similar to the Google C++ style guide, except in cases where the code has been formatted in a more readable way, such as when aligning parts in a table. The Standard C++ Foundation guidelines offer some advice about formatting conventions that are informative, particularly regarding the use of code comments. For tools to help with formatting code, see the section 1.3. 1.2.4 R-specific coding advice Prefer to use the double-bracket operator (list[['element']]) rather than the dollar-sign operator (list$element) when accessing the elements of a list. The $ operator uses partial matching, whereas [[, by default, does not. (However, it can be specified: list[['element', exact = FALSE]].) Avoiding partial matching by using [[ gives us more confidence that errors won’t occur. While there is no inherent performance difference between a for loop and an apply-type function such as apply or lapply (the apply functions actually use for loops in their source code), it is nevertheless possible to write a “bad” for loop that runs slowly. Common culprits include a failure to pre-allocate memory or a poor choice in assignment method. If a for loop seems to run slowly, consider replacing it with an apply-type function or tweaking the assignment method (e.g. replacing append with [). Many guides for optimizing loop performance are available online, such as Strategies to Speedup R Code and Why loops are slow in R. 1 The Linux kernel project recently changed the default length for code lines from 80 to 100 characters with the following commit comment: Yes, staying withing 80 columns is certainly still preferred. But it’s not the hard limit that the checkpatch warnings imply, and other concerns can most certainly dominate. Increase the default limit to 100 characters. Not because 100 characters is some hard limit either, but that’s certainly a “what are you doing” kind of value and less likely to be about the occasional slightly longer lines. ↩︎ 1.3 Formatting Tools 1.3.1 Clang’s formatting tool Many of these BioCro formatting preferences can be applied automatically using the program clang-format with the .clang-format file provided in the base directory of BioCro. Do not apply clang-format to all files indiscriminately, as that will ruin manually-aligned tables. The best time to reformat a file is immediately before (or possibly immediately after) making substantive changes to the code in the file. But, as mentioned in Section 1.2.2, sweeping formatting changes should be made in a separate commit, separate from any substantive changes made to the code. This way, changes to the functioning of the code won’t be obscured by changes to formatting that have no effect on code semantics. 1.3.1.1 Installation One can install clang-format on Ubuntu using sudo apt install clang-format. On macOS, clang-format is available from the Homebrew package manager. 1.3.1.2 Using the Clang formatting tool Files can be formatted using clang-format file_name &gt; new_file or edited in place using clang-format -i file_name If your editor has the ability to display differences between the original and revised versions of the file, it is a good idea to step through and inspect the proposed changes to ensure they are desirable. 1.3.1.3 Using the Clang formatting tool with the CodeLite IDE On Windows, macOS, or Linux, the CodeLite IDE includes clang-format and provides an easy way to use it. First go to Plugins -&gt; Source Code Formatter -&gt; Options. In the C++ tab, select use .clang-format file. Now press Ctrl-I or click Plugins -&gt; Source Code Formatter -&gt; Format Current Source to format a file. 1.3.2 EditorConfig Another tool to help with formatting is EditorConfig. EditorConfig, when used in conjunction with the .editorconfig file provided in the base directory of BioCro, provides a method for standardizing settings across different text editors. While some editors have native support, others require a plugin. See the EditorConfig website for more details. As of this writing, no C++ API for BioCro has been defined: there is no document that makes clear what publicly accessible portions of the framework and standard library are guaranteed to remain stable and available to be programmed against and which portions are subject to change.↩︎ Irrespective of what dependencies BioCro now has or are added to it, a researcher who is concerned about reproducability should consider making a containerized version of BioCro. See, for example, the chapter Docker and Reproducibility in the document for the workshop Reproducible analysis and Research Transparency. The BioCro maintainers don’t provide containerized versions of BioCro as we think this is a task better left to the individual researcher.↩︎ BioCro’s strong dependencies are the R framework, the C++ compiler used in installing the BioCro package, the C++ Standard Library, the and the Boost C++ Library. As for R package dependencies, the BioCro R package depends only upon packages in the R standard library (stats and utils) for its basic installation and functioning. BioCro does use other, non-standard R packages for building the vignettes (knitr) and for testing (testthat), but these are not essential to a fully-functioning BioCro installation. For further reading on the benefits and pitfalls of using dependencies, see, for example, Russ Cox’s article Our Software Dependency Problem and Bill Sourour’s article Code dependencies are the devil.↩︎ "],["generating-documentation.html", "2 Generating Documentation 2.1 Online documentation 2.2 When to generate documentation 2.3 Documenting the C/C++ code. 2.4 Building package vignettes 2.5 Compiling and viewing the bookdown book", " 2 Generating Documentation 2.1 Online documentation Before we discuss generating documentation, we reiterate that you rarely need to. That is because the documentation is automatically generated for you and made available online! The documentation landing page at https://ebimodeling.github.io/biocro-documentation/ links to up-to-date documentation for the latest version of BioCro on the master branch (of the ebimodeling/biocro GitHub repository), plus select documentation for versions on other branches. 2.2 When to generate documentation For the most part, developers should only need to generate documentation when they wish to check how changes made to it will be rendered, and whether that rendering is more or less correct. Changes a developer might make to the documentation include: Changes to Doxygen-style comments in the C++ source code files Changes to R function and data documentation (the files in the man directory) Changes to any of the Markdown (.md) or R Markdown (.Rmd) files included in the Bookdown book (this book). (A list of all files used in forming the Bookdown book is in the configuration file bookdown/_bookdown.yml.) Changes to the vignettes In most other cases, developers can simply consult the automatically-generated online version of the documentation. 2.3 Documenting the C/C++ code. To generate documentation for the C/C++ code, we use Doxygen. 2.3.1 Use cases for generating the Doxygen documentation As mentioned in Section 2.2, developers should rarely need to generate documentation themselves since all of the documentation is regularly generated and published on-line. But there are cases where it makes sense to “do it yourself.” For Doxygen, these include: You are altering the code or documentation of a particular C++ source file, and you want to check that changes you make show up correctly in the generated documentation. You want a local copy of the Doxygen documentation because you don’t want to rely upon always having an internet connection. You are making large-scale changes to the code, and it would be useful to have a version of the documentation that tracks with your changes. You prefer a different presentation style for the documentation than is used in the on-line version. Use Cases 2 and 3 are best addressed using the simple methods of Section 2.3.4. Use Case 1 is greatly facilitated by speeding up Doxygen using the methods discussed in Section 2.3.5. Lastly, Use Case 4, which requires a more extensive knowledge of Doxygen, is discussed in Section 2.3.6. If none of these use cases apply to you, you most likely can simply use the on-line documentation and skip the rest of this chapter. 2.3.2 Required software Doxygen (version 1.9.2 or higher) The Graph visualization toolkit (“GraphViz”; version 2.38 or higher) You can get by without this if you don’t care about generating the dependency and inheritance graphs. If you don’t have GraphViz installed, set “HAVE_DOT = NO” in the customization file (see below). A LaTeX distribution This is needed only if you set USE_MATHJAX = NO, or if you want to generate the PDF version of the documentation. Ghostscript You may be able to get by without this. You will need it, however, if you wish to generate HTML documentation that doesn’t rely on MathJAX.8 Gnu Make (version 4.3 or higher)9 This is needed only if you want to take advantage of the Makefile recipes. 2.3.3 Installation Binary distributions of Doxygen for Linux x86-64, for Windows (Vista and later), and for macOS (10.14 and later) are available on the Doxygen Downloads page. To compile Doxygen from source, see the Doxygen Installation page. If you use a package manager, installation is quite easy. For example, running sudo apt-get install doxygen graphviz ghostscript on Ubuntu will get you not only Doxygen, but Ghostscript and the Graph visualization toolkit as well. (To do something similar on a Mac with Homebrew, run brew install doxygen graphviz ghostscript.) Depending on your system setup and operating system, you may additionally need to take pains to ensure that all required tools—gs, make, dot (from Graphviz), and doxygen itself—are on your system path. 2.3.4 Generating the Documentation If you have Make installed By far the easiest way to generate the complete Doxygen documentation with more or less the same customizations as appear in the on-line version is to open a terminal to the doxygen directory and run make all-html (Since all-html is the default Make target, you can also simply type make.) This will generate the most complete HTML version of the Doxygen documentation.10 To view it, open your browser to the landing page for the documentation, located at doxygen/doxygen_docs_complete/html/index.html. (On many systems, typing make view will generate the documentation and open it in a browser in a single step.) There are other Make targets available. To see a list, run make help These other Make targets may be useful if you want a PDF version of the documentation; or if you want to concentrate on the documentation of the BioCro modules only, or conversely, on only the C++ BioCro framework. If you don’t have Make installed Doxygen can be run directly by simply opening a terminal to the doxygen directory and typing doxygen on the command line. This produces almost the same results as running make. The differences are The browser won’t automatically open the documentation, as it does when you run make view. The About page won’t show information from Git about the state your working copy of the BioCro repository was in at the time you generated the documentation. The location of the generated documentation’s landing page will be doxygen/html/index.html rather than doxygen/doxygen_docs_complete/html/index.html. The canned Doxygen customization sets provided by Makefile are not available when you run doxygen directoy. 2.3.5 Speeding up Doxygen Method 1 By far, the most time consuming part of generating the Doxygen documentation is creating the graphs showing relationships between program components. You can speed up Doxygen tremendously by disabling the generation of these graphs. This is particularly recommended if you are tweaking the documentation of some source code and want to quickly see how your changes affect the rendered documentation (see the first use case in Section 2.3.1). To disable generation of graphs: Create a file called Doxyfile in the directory doxygen/customizations. Insert the single line HAVE_DOT = NO into this file. (If doxygen/customizations/Doxyfile already exists, simply add the line HAVE_DOT = NO to it.) Doing these two steps will override the setting HAVE_DOT = YES contained in doxygen/Doxyfile. (Bash shell users can disable graph generation for a single call of doxygen by running the command (cat Doxyfile; echo &quot;HAVE_DOT = NO&quot;) | doxygen - in the doxygen directory. If you use a different shell, see the question Can I configure doxygen from the command line? in the Doxygen FAQ.) Once you are satisfied with the way your Doxygen comments are rendered, you can, if you like, generate the documentation with the graphs by removing the HAVE_DOT = NO line from doxygen/customizations/Doxyfile.11 Method 2 Another way to speed up Doxygen is to run it only on the particular file whose documentation you are tweaking. For example, if you are adding to or changing the documentation in the source file src/module_library/partitioning_coefficient_logistic.h you can simply run (cat Doxyfile; echo &quot;INPUT=../src/module_library/partitioning_coefficient_logistic.h&quot;) | doxygen - in a Bash shell from the doxygen directory.12 This will run almost instantaneously! (The down side is that you will only be able to view the documentation pertaining to that particular file. You won’t, for example, be able to click on links to parent classes or dependent files and see the related documentation of those program entities.) 2.3.6 Doxygen for power users: Customizing Doxygen builds This section addresses Use Case 4 of Section 2.3.1. As we saw in Section 2.3.5, we can customize Doxygen runs by adding settings to the file doxygen/customizations/Doxyfile. For example, adding HAVE_DOT = NO to this file will override the setting HAVE_DOT = YES contained in doxygen/Doxyfile. Doxygen offers dozens of settings that allow one to customize the generated documentation according to one’s preferences. We will highlight just a few of these settings that may be of special interest. For a complete list, see the Configuration section of the Doxygen documentation. INPUT We saw this setting in Section 2.3.5, where we used it to override the default setting (which looks at all of the C++ source files) in order to concentrate on a particular file. This vastly reduced Doxygen’s running time. Note that multiple files (or directories!) may be listed here: simply separate the names with a space. Alternatively, list each on a separate line, using INPUT += on all but the first line. For example, INPUT = ../src/module_library/partitioning_coefficient_logistic.h INPUT += ../src/framework will yield documentation of the partitioning_coefficient_logistic module plus documentation of all of the source files in the src/framework directory. Note that the Make-file recipes ignore settings made to INPUT in the Doxyfiles. You will have to call doxygen directly for these settings to have any effect. Note also that Doxygen does not automatically recurse into subdirectories. For example, to also document the contents of src/framework/utils, you would need to add a third line: INPUT += ../src/framework/utils GENERATE_TREEVIEW The setting in doxygen/Doxyfile is YES. Since the Tree View index takes up screen width, setting this value to NO may facilitate easier browsing of source code. As with INPUT, the Make-file recipes normally override any setting made to this variable in the Doxyfiles. For this variable however, the value may be overridden on the command line using a call to Make of the form make generate_treeview=NO &lt;make target&gt; (see the note below). Or, simply call doxygen directly as in the INPUT case. HAVE_DOT As we saw in the previous section, setting this to NO will vastly reduce compilation time. (You should also set this to NO if you don’t have a copy of GraphViz, the package that contains the dot tool!) Unlike with INPUT and GENERATE_TREEVIEW, Make does respect the value this is set to in the Doxyfiles. For finer-grained control over which diagrams get generated, see the Doxygen documentation section Configuration options related to the dot tool. The doxygen/customizations directory contains a sample customization file named Doxyfile_customization_sample containing some suggestions for customizing your own Doxygen builds. To use this as a template, copy it to a file named Doxyfile (in the same directory) and modify it as you see fit. Note on customizing Make builds Certain customization variables are off limits when building the documentation using Make. These include the following: GENERATE_HTML, GENERATE_TREEVIEW, GENERATE_LATEX, INPUT, OUTPUT_DIRECTORY, EXTRACT_PRIVATE, and HTML_COLORSTYLE_HUE. If any of these tags are set in the customization file doxygen/customizations/Doxyfile, those settings will be ignored when using Make. This is because the Make file itself sets values for these variables, overriding any settings in the Doxyfiles. Three of these variables, however, can be set on the command line when running Make. This is done as follows: GENERATE_TREEVIEW To override the value YES that is set in Makefile, add a variable setting to the make command: make generate_treeview=NO &lt;make target&gt; HTML_COLORSTYLE_HUE To override the value 143 that is set in Makefile, add a variable setting to the make command. For example make color=30 &lt;make target&gt; For the meaning of the hue number, see the Wikipedia article on this subject.13 EXTRACT_PRIVATE To override the value YES that is set in Makefile``, add a variable setting to themake` command: make extract_private=NO &lt;make target&gt; This will produce documentation that focuses on the public API for classes, omitting documentation of private class members. 2.4 Building package vignettes 2.4.1 Required software Unless you only want to build vignettes written in Markdown (“.Rmd” files), you will need a TeX installation of some sort. Here are two options: Visit the CTAN starter page and choose and install a TeX distribution designed for your platform. Alternatively, if you mainly want a TeX installation for use in R, you can install the R tinytex package along with some extra needed LaTeX packages not included in TinyTeX by default by proceeding as follows: install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # Install a few LaTeX packages needed by the vignettes but not # included in tinytex: tinytex::tlmgr_install(c(&#39;siunitx&#39;, &#39;babel-english&#39;, &#39;footnotebackref&#39;, &#39;listings&#39;, &#39;appendix&#39;, &#39;pgf&#39;)) (If you install TeX in this way, you will either need to build the vignettes using one of the Alternative options given below or add TinyTex’s bin directory to your shell path. You can find the root of the TinyTex installation with the R function tinytex::tinytex_root().) If you use the second alternative build option listed below, you will also need the R package devtools: install.packages(&#39;devtools&#39;) 2.4.2 Build procedure The following instructions assume that the root of the BioCro source tree is a directory named biocro. Build the package by running R CMD build biocro from the command line in the directory containing biocro. This includes building the vignettes. Then install using R CMD INSTALL BioCro_xxx.tar.gz, where xxx is the version number. The vignettes should now be available as HTML or PDF files located in path_to_rlib/BioCro/doc, where path_to_rlib is the path to your R library directory. An easy way to pull up an index to the vignettes in a web browser is to run the command browseVignettes('BioCro') in an R session. 2.4.3 Alternative options Here are some alternative methods of building vignettes that don’t require re-installing BioCro. From an R session running in biocro/vignettes, type tools::buildVignette(XXX), where XXX is the name of the particular vignette you wish to build. (It should have extension .Rnw or .Rmd.) The resulting PDF or HTML file will appear in biocro/vignettes. This method is relatively fast and so is especially useful if you are writing a new vignette or revising an existing one. If the vignette being built uses any BioCro code, there must be a version of BioCro installed. From an R session running in any directory of the BioCro source tree, type devtools::build_vignettes(). (Alternatively, start R from anywhere and pass the path to BioCro source tree as the first (“pkg”) argument to build_vignettes().) This method will modify .Rbuildignore and .gitignore, which may be annoying. The resulting HTML and PDF files will appear in the doc directory, which will be created if it doesn’t already exist. This method doesn’t require that BioCro be installed. But it builds and installs BioCro in a temporary location and then builds all the vignettes, and thus it can be somewhat time consuming. Moreover, by default it gives very little indication of build progress, and so it may be useful to override this default and set quiet = FALSE in the function argument list. 2.5 Compiling and viewing the bookdown book Note: A copy of the bookdown BioCro development manual is automatically generated on BioCro’s GitHub documentation site at https://ebimodeling.github.io/biocro-documentation/bookdown_book/index.html. So what follows is likely primarily of interest to developers wishing to revise this book who want to be able to easily view the result of their revisions before committing them. To generate the bookdown BioCro development manual, do as follows: Install Pandoc, if it is not already on your system. See https://pandoc.org/installing.html for instructions. (Note to RStudio users: As mentioned in the R Markdown Cookbook (https://bookdown.org/yihui/rmarkdown-cookbook/install-pandoc.html), RStudio comes with its own copy of Pandoc, so you may be able to get by without installing it separately.) Install the R bookdown package, if it hasn’t been installed already. These instructions are written for bookdown version 0.22 or greater but may work for other versions. In the bookdown directory of your BioCro source tree, run Rscript -e &quot;bookdown::render_book()&quot; Note: If you wish to run render_book from other than the bookdown directory, you may pass a path argument: Rscript -e &quot;bookdown::render_book(&lt;path&gt;) Here, &lt;path&gt; denotes the path from the current directory to the bookdown directory. This only works in bookdown versions 0.22 and later! With earlier versions, you can make use of the xfun::in_dir function: xfun::in_dir(&#39;&lt;path&gt;&#39;, bookdown::render_book()) Again, &lt;path&gt; here denotes the path from the current directory to the bookdown directory. Note: Because some sections of the book are contained in their own files rather than being in a larger file comprising a complete chapter, render_book will issue a warning such as the following, which may be safely ignored: \"In split_chapters(output, gitbook_page, number_sections, split_by, : You have 13 Rmd input file(s) but only 7 first-level heading(s). Did you forget first-level headings in certain Rmd files?\" In a Web browser, open bookdown/_book/index.html. Ghostscript is used to convert the PostScript files that are generated for formulas in the documentation into bitmaps. But MathJax provides an alternative method of rendering formulas in the HTML documentation, and so Ghostscript is unneeded as long as the Doxygen configuration variable USE_MATHJAX is set to YES. This is the BioCro default setting. If Ghostscript is used, there may be some compatibility issues between Ghostscript and Doxygen. If you encounter problems, see Doxygen issue #7290 and Doxygen issue #8107 for further information. On the other hand, use of MathJax requires a working internet connection, at least until your browser downloads and caches the MathJax code file. And it requires that JavaScript be enabled.↩︎ Although versions earlier than 4.3 will probably mostly work, you will get a warning when you use them.↩︎ Some users will have to type gmake in place of make to get the latest version of Gnu Make. Type make --version or gmake --version to see exactly what version you are calling.↩︎ If you are compiling the documentation using Make and haven’t changed any source files since last running it, add the -B option to force recompilation.↩︎ Alternatively, if you will be working extensively with one particular file, you could temporarily add INPUT=../src/module_library/partitioning_coefficient_logistic.h to the customization file (doxygen/customizations/Doxyfile). Then you would simply run doxygen from the doxygen directory. Note that even though the customization file is in the doxygen/customizations directory, the file paths listed in the INPUT value should be relative to the doxygen directory!↩︎ Other settings that affect the color of the documentation are HTML_COLORSTYLE, HTML_COLORSTYLE_SAT, and HTML_COLORSTYLE_GAMMA. The values for these options must be set in the customization file doxygen/customizations/Doxyfile if using Make; alternately, if calling doxygen directly, they may be set on the command line; for example (cat Doxyfile; echo &quot;HTML_COLORSTYLE_SAT=255&quot;) | doxygen - See the Configuration section of the Doxygen documentation for information about these settings.↩︎ "],["running-the-testthat-tests.html", "3 Running the testthat Tests 3.1 Requirements 3.2 tl;dr 3.3 tl;dr for devtools users 3.4 Continuous integration workflow; why run tests manually? 3.5 Test-running scenarios 3.6 Running individual test files 3.7 Using devtools", " 3 Running the testthat Tests 3.1 Requirements The testthat package. From the R command line, run install.packages('testthat'). 3.2 tl;dr To run all testthat tests, move to the tests directory within the BioCro source code directory tree and run Rscript testthat.R Warning: This assumes the BioCro package has been installed. It will run all tests in the tests/testthat directory against this installed version. If you want the tests to reflect changes to your source code, reinstall BioCro before running them, or use one of the alternative test-running methods outlined below. 3.3 tl;dr for devtools users If you use the devtools package, you can run all tests by doing the following command in any directory in the BioCro source tree: Rscript -e &quot;devtools::test()&quot; This will test against the source code; it does not expect BioCro to be installed. Note that this source code test will compile or recompile the C++ code if necessary. See the source-code testing section (Section 3.5.3) for details. 3.4 Continuous integration workflow; why run tests manually? BioCro’s testthat test suite is automatically run on GitHub as part of the R-CMD-check workflow every time a BioCro developer pushes code to the GitHub master branch. (Users also have the option to trigger this workflow manually by clicking a button on GitHub.) Workflow results are viewable on GitHub under the repository’s Actions tab. There are (at least) two scenarios, however, under which you may want to run tests manually: You have revised the package’s R code, stored data, or C++ code, and you want to run the testthat test suite against the changed code on your own machine before pushing that code to GitHub. You are writing new tests, and you want to ensure that they work as expected. Read on for further information about various topics, including testing package source versus testing an installed package better test reporting options running individual test files 3.5 Test-running scenarios There are two main ways to run the BioCro testthat tests: Run tests in the tests/testthat directory of a BioCro source tree against an installed version of BioCro Run tests in the tests/testthat directory of a BioCro source tree against the code in that source tree (A third scenario exists: running installed testthat tests against the installed package. But currently the BioCro package does not install any of its tests.) 3.5.1 Running the test suite on the installed version of BioCro As explained in the tl;dr section above (Section 3.3), the easiest way to run the tests against an installed version of the BioCro package is to move to the tests directory within the BioCro source code directory tree and run Rscript testthat.R Alternatively, the tests may be run inside an R session as follows: Start an R session (if you don’t have one open already). Run xfun::in_dir('&lt;path to tests directory&gt;', source('testthat.R')), where &lt;path to tests directory&gt; is the path to the tests directory of a BioCro source tree. OR Use setwd to move to the tests directory (if you aren’t there already) and just run source('testthat.R'). Either of these methods will run the testthat tests in the same way that R CMD check would run them. (But R CMD check builds BioCro immediately before running the tests, ensuring that you are running the tests against a version of the BioCro package corresponding to the BioCro code in your source tree.) 3.5.2 Switching reporters The default output of the test method used by testthat.R can be exceedingly terse, and so it is highly desirable to tweak the test output of that method for interactive use. This is done by overriding the default reporter of the testing function using the reporter argument. A particularly useful and informative reporter is the Summary reporter. To use it, run the following commands in an R session: library(BioCro) library(testthat) xfun::in_dir(&#39;&lt;path to tests directory&gt;&#39;, test_check(&#39;BioCro&#39;, reporter = &#39;Summary&#39;)) (If you are in the tests directory, the third line can be simply test_check(&#39;BioCro&#39;, reporter = &#39;Summary&#39;) And if you have already loaded the BioCro and testthat packages (either directly or by sourcing testthat.R), there is no need to reload them!) The Summary reporter is useful in two ways: It clearly indicates testing progress by printing a character to the screen each time a test completes (“.” for success, “S” for a skipped test, “W” for a warning, and an (error) number for a failed test). And it prints the file name of each test file before printing that file’s context message. Setting reporter to ‘Progress’ yields slightly less verbose output. Crucially and inconveniently, it doesn’t print the names of the test files being run, although it does print their context messages. On the other hand, it gives a better numerical summary of the test results—how many tests passed, how many failed, and how many were skipped.14 3.5.3 Running the test suite against the BioCro source code If you are making changes to the R code or to the C++ code (or even to the package data) and you want to test your changes to the source code without installing (or re-installing) the BioCro package, the function to use is test_local.15 The steps are similar to the steps above for running test_check: Start an R session. Load the testthat library: library(testthat). (Note that we don’t need to load the BioCro library, and there needn’t even be a copy of it installed!) Run test_local('&lt;path to the tests directory of some BioCro source tree&gt;') If you are actually in the tests directory—either because you started R there or because you moved there with setwd—you can just run test_local(), because the path defaults to '.'. Note that this function expects to find an up-to-date copy of the BioCro C++ library file (BioCro.so, or BioCro.dll on Windows) in the src directory. If it doesn’t find it (or if it is out of date with respect to the C++ source files), it will try to re-create it. (This will happen even if none of the tests use any of the package code.) So be patient if the function seems to hang for several minutes while it does this! The default reporter for test_local is the Progress reporter, but if you prefer the Summary reporter, which gives better progress indication and prints the name of each test file it runs, you can switch: test_local(&#39;&lt;path to the tests directory of some BioCro source tree&gt;&#39;, reporter = &#39;Summary&#39;)` 3.6 Running individual test files While writing new tests, it is useful to be able to run a single test file rather than the whole test suite. The test may be run either against the installed version of the BioCro package, or against the source code. 3.6.1 Running an individual test file on the installed package Method 1 Start an R session. Load the BioCro and testthat packages: library(BioCro) library(testthat) Call the test_file function on the path to a test file: test_file(&#39;&lt;path to test file to run&gt;&#39;) Note the path passed to test_file can be either a relative or an absolute path. It doesn’t matter what directory the R session was started in or what the current R directory is as long as the path is correct. Making the testthat directory the current directory, however, will make for shorter path names. Once again, the default reporter (“CompactProgress”, in this case) may be overridden: test_file(&#39;&lt;path to test file to run&gt;&#39;, reporter = &#39;Summary&#39;) See the documentation for testthat::Reporter for a list of reporters. Method 2 This uses the test_check function we used earlier (see Section 3.5.2), but with a “filter” option. Start an R session. Load the BioCro and testthat packages: library(BioCro) library(testthat) Call the test_check function with a filter option to select the desired test file. The filter pattern should be a regular expression matching the main part of the test file. For example, to run the tests in test.HarmonicOscillationModeling.R, we could setwd to the tests directory and call test_check as follows: test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;) The filter matching is performed on file names after they are stripped of “test-” and “.R”. Again, a reporter option may be specified. For example, test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;, reporter = &#39;Summary&#39;) Note that step 3 assumes you are in the BioCro tests directory when test_check is called. If you aren’t, either usesetwd get there first, or use the xfun::in_dir wrapper: xfun::in_dir(&#39;&lt;path to tests directory&gt;&#39;, test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;)) 3.6.2 Running an individual test file against the package source code Again, the test_local function is used. The method is exactly the same as specified above in section 3.5.3 except that a filter option is used to limit testing to matching files (see Method 2 in the previous section). 3.7 Using devtools If you don’t mind installing and using the devtools package, it provides a particularly easy way to run tests against the package source code: simply issue the following command in any directory in the BioCro source tree: Rscript -e &quot;devtools::test()&quot; Again, the filter option may be used with this function to limit the tests run, and the default reporter may be overridden with the reporter option. The names “Progress” and “Summary” almost seem to me as if they have been reversed! After all, it is the Summary reporter which most clearly indicates how the testing is progressing and the Progress reporter that gives the best numerical summary of how many tests failed.↩︎ Or you can use devtools::test(). See tl;dr for devtools users and Using devtools.↩︎ "],["adding-the-boost-libraries.html", "4 Adding the Boost libraries 4.1 Why this is needed 4.2 How to extract parts of Boost", " 4 Adding the Boost libraries 4.1 Why this is needed BioCro uses software from the Boost C++ libraries. Boost does not assure backward compatibility, so changes to Boost could break BioCro. Thus, we don’t want to link our code to a user supplied Boost installation, and we include a version with BioCro. Boost is very large, so we want to include only the necessary parts. This document lists steps to extract the relevant parts and update files in BioCro to use them. 4.2 How to extract parts of Boost Use the bcp tool included with Boost to extract parts of the Boost library. bcp accepts a list of files or modules and extracts the relevant parts of the Boost library to a directory. The boost files that BioCro uses are as follows: File name Notes boost/config.hpp Used in module_dependency_utilities.cpp boost/graph/adjacency_list.hpp Used in module_dependency_utilities.cpp boost/graph/topological_sort.hpp Used in module_dependency_utilities.cpp boost/math/constants/constants.hpp Used in constants.h boost/numeric/odeint.hpp Used in ode_solver.h boost/numeric/ublas/io.hpp Used in newton_raphson_boost.h boost/numeric/ublas/lu.hpp Used in newton_raphson_boost.h boost/numeric/ublas/matrix.hpp Used in newton_raphson_boost.h boost/numeric/ublas/triangular.hpp Used in newton_raphson_boost.h boost/numeric/ublas/vector.hpp Used in boost_ode_solvers.h boost/numeric/ublas/vector_proxy.hpp Used in newton_raphson_boost.h boost/typeof/incr_registration_group.hpp This is needed for boost/units but is not exported properly boost/graph/detail/empty_header.hpp This is needed for topological_sort but is not exported properly Note that we do not actually use boost/units, but it is included whenever boost/numeric/odeint.hpp is included, and BioCro will not compile on some operating systems without it. Hence the need for boost/typeof/incr_registration_group. Run the following command, noting that the path to the temporary directory must exist: bcp --boost=\"PATH_TO_BOOST_ROOT_DIRECTORY\" \"boost/config.hpp\" \"boost/graph/adjacency_list.hpp\" \"boost/graph/topological_sort.hpp\" \"boost/math/constants/constants.hpp\" \"boost/numeric/odeint.hpp\" \"boost/numeric/ublas/io.hpp\" \"boost/numeric/ublas/lu.hpp\" \"boost/numeric/ublas/matrix.hpp\" \"boost/numeric/ublas/triangular.hpp\" \"boost/numeric/ublas/vector.hpp\" \"boost/numeric/ublas/vector_proxy.hpp\" \"boost/typeof/incr_registration_group.hpp\" \"boost/graph/detail/empty_header.hpp\" PATH_TO_TEMPORARY_DIRECTORY Copy PATH_TO_TEMPORARY_DIRECTORY/boost to the inc directory, overwriting any previous version of boost. Other files and directories my be created in PATH_TO_TEMPORARY_DIRECTORY, but they are not needed. Check that the Boost license in inc is correct for the version used, and update the package LICENSE file if necessary. Update the path to the Boost license in the package LICENSE file. Run R CMD check and truncate any boost file paths that are flagged as exceeding 100 characters. Be sure to update any associated #include directives that reference these files; otherwise, compilation errors will occur. See commit 9620b2b994c4dbe0421354cd2c52a82eb170a96 for an example. 4.2.1 Notes for using bcp in Windows First, follow the instructions in the “Getting Started on Windows” Boost page. For V1.71.0, this entails the following: - Install the Visual Studio 2019 Developer Command Prompt (see here). Download the full Boost library, unzip it, and put it somewhere convenient: e.g., C:\\Program Files\\boost\\boost_1_71_0. Open a VS developer prompt and cd into the boost root directory: e.g., cd C:\\Program Files\\boost\\boost_1_71_0. Type bootstrap and press enter. This may take a minute or so to complete. Type .\\b2 and press enter. This may also take a little while. Now the Boost libraries have been built, and we are almost ready to use bcp. However, we need to explicitly build the bcp tool using the Boost.Build tool, which is cryptically named b2.exe. In a VS developer prompt, cd into the tools/bcp directory: e.g., cd C:\\Program Files\\boost\\boost_1_71_0\\tools\\bcp. Run b2.exe using its full path: e.g., type C:\\\"Program Files\"\\boost\\boost_1_71_0\\b2 and press enter. Now bcp.exe should be in C:\\Program Files\\boost\\boost_1_71_0\\dist\\bin. Finally, cd into the folder that contains bcp: e.g., cd C:\\Program Files\\boost\\boost_1_71_0\\dist\\bin. Now you should be able to run the command listed as “Step 1” above from a VS developer command prompt. "],["the-update-documentation-workflow.html", "5 The Update Documentation Workflow", " 5 The Update Documentation Workflow This workflow, Update Documentation, runs Doxygen in various configurations on the BioCro C++ Library source code and copies and commits the result to the repository given as the value of the “PUBLISH_TO” environment variable, currently “ebimodeling/biocro-documentation”. That repository is, in turn, set up to publish to a GitHub Pages Web site at the corresponding canonical location (currently, https://ebimodeling.github.io/biocro-documentation/). The workflow runs whenever changes to the C++ source files or the files implementing this workflow are checked into the master branch. It may also be run manually on the GitHub site. In order for this to all work correctly, a number of set-up steps were required: An SSH public/private key pair was generated on a work station using the command ssh-keygen -t rsa -b 4096. (Use the -C option to include a comment. Use an empty pass-phrase) This key pair is used in order to allow a workflow defined in this repository to push files to a different repository (namely, “ebimodeling/biocro-documentation”); see steps 2 and 6 below. The private key was added as a secret in the ebimodeling/biocro repository (this repository) under the key PRIVATE_SSH_KEY. (See https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository. The key name matches the reference secrets.PRIVATE_SSH_KEY used in the document.yml workflow file.) The “ebimodeling/biocro-documentation” repository was created. A README.md file was added to the top-level directory of this new repository with (relative) links pointing to the (prospective) locations of various versions of the documentation. GitHub Pages was enabled for the “ebimodeling/biocro-documentation” repository (see https://pages.github.com/). This results in the files in this repository getting automatically published as a Web site to the URL https://ebimodeling.github.io/biocro-documentation/. The public SSH key was added as a deploy key to the “ebimodeling/biocro-documentation” repository under the name “Access from ebimodeling/biocro actions”. (See https://docs.github.com/en/developers/overview/managing-deploy-keys#setup-2. The name “Access from biocro action” is for informational purposes only and has no programmatic significance.) "],["the-doxygen-docker-action-using-makefile-action.html", "6 The Doxygen Docker Action using Makefile Action 6.1 Inputs", " 6 The Doxygen Docker Action using Makefile Action This action is a customization of the code found at https://github.com/mattnotmitt/doxygen-action. Instead of calling Doxygen directly, it assumes that there is a Make file in the working directory that invokes Doxygen to build the documentation. 6.1 Inputs 6.1.1 ‘working-directory’ Required Path of the working directory to change to before running Make. This should be the location of the Make file used with Doxygen. 6.1.2 ‘color’ Optional The color setting (given as an angle from 0 to 360 in the HSL/HSV color space). Default: 143 (greenish) 6.1.3 ‘document-private’ Optional YES to document private class members, NO to document only the public and protected ones. Default: YES 6.1.4 ‘generate-treeview’ Optional YES to generate the Tree View index, NO to omit it. Since the Tree View index takes up screen width, omitting it may facilitate easier browsing of source code. Default: YES 6.1.5 ‘extra-settings’ Optional A space-separated set of settings of the form key=value. Only keys recognized by the make file will have any effect. Example: module_docs_directory=doxygen_docs_modules_public_members_only will change the output directory for module-docs-* targets from doxygen_docs_modules to doxygen_docs_modules_public_members_only. Default: ’’ (blank) 6.1.6 ‘makefile-target’ Optional The name of the Make target to use. Default: ’’ (none) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
